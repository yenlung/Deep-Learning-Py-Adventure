{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 讀入 MNSIT 數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下要由 datasets 中的 MNIST 讀入訓練資料, 注意參數中 \n",
    "\n",
    "* `'./data'` 是說下載後存在 `data` 資料夾\n",
    "* `train=True` 意思是這是訓練資料\n",
    "* `download=True` 意思是要下載到我們的磁碟機中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18b9135b50c4ae4ac11cadf524d05f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b01f4983744206bef3fdd0f13dd310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdab84e391e74e9780479ebe5ef93c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528c46880dd34b5f8f088913fd4cf0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yenlung/anaconda3/envs/torch-py37/lib/python3.7/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST('./data', train=True,  \n",
    "                             download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "測試資料讀入應該就沒有問題了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = datasets.MNIST('./data', train=False,  \n",
    "                             download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 你也可以讀入 Fasion 版的 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 欣賞數據集內容 (非執行必要)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_train = len(mnist_train)\n",
    "no_test = len(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有 60000 筆訓練資料,\n",
      "及 10000 筆測試資料。\n"
     ]
    }
   ],
   "source": [
    "print(f\"有 {no_train} 筆訓練資料,\")\n",
    "print(f\"及 {no_test} 筆測試資料。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸入放在 `data`, 輸出放在 `targets` 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1732\n",
    "\n",
    "X = mnist_train.data[n]\n",
    "Y = mnist_train.targets[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標記正確答案為 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X, cmap='Greys')\n",
    "print(f\"標記正確答案為 {Y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 資料整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原本 $28 \\times 28$ 的矩陣, 我們改為 784 維的向量, 並且都除以 255。要注意在 `pytorch` 的 tensor 運算中, 255 要很明確的告訴 `pytorch` 是浮點數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mnist_train.data.reshape(no_train, 784) / 255.\n",
    "x_test = mnist_test.data.reshape(no_test, 784) / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再來是訓練和測試資料的輸出 (正確答案)。這裡有個 `pytroch` 小技巧, 就是等等我們用 Cross Entropy 當 loss function 的時候, `pytorch` 不需要把我們這些輸出改為 one-hot encoding, 計算時自動會依 one-hot encoding 去計算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mnist_train.targets\n",
    "y_test = mnist_test.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. step 1: 打造神經網路\n",
    "\n",
    "打造神經網路和 `tf.Keras` 風非常像! 如果要做兩層隱藏層, 各 100 個神經元是這樣做的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次注意輸出層沒有用 `Softmax`, 這是 (再一次) `pytorch` 的 Cross Entropy 就內建了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義 (選擇) 我們的 loss function 和優化方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=0.087)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. step 2: 訓練\n",
    "\n",
    "我們先來慢動作做一次! 現在我們的 model 就是我們函數學習機, 已經可以動作! 於是我們要計算 loss, 當然是..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = loss_fn(predict, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可欣賞一下 loss 大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2964, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這時我們可以對 loss 做 gradient descent, 不過因為每次要調的大小預設是累進的, 所以我們要做個 gradient 歸零的動作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著對 loss 做 backpropagation。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再把參數更新!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算一下正確率..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predict_class = torch.max(predict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (predict_class == y_train).sum() / float(no_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前正確率 16.82%\n"
     ]
    }
   ],
   "source": [
    "print(f\"目前正確率 {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在合起來做!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前正確率 90.00%\n",
      "目前正確率 90.01%\n",
      "目前正確率 90.01%\n",
      "目前正確率 90.03%\n",
      "目前正確率 90.04%\n",
      "目前正確率 90.05%\n",
      "目前正確率 90.06%\n",
      "目前正確率 90.06%\n",
      "目前正確率 90.05%\n",
      "目前正確率 90.06%\n"
     ]
    }
   ],
   "source": [
    "predict = model(x_train)\n",
    "\n",
    "for i in range(10):\n",
    "    loss = loss_fn(predict, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    predict = model(x_train)\n",
    "    _, predict_class = torch.max(predict, 1)\n",
    "    acc = (predict_class == y_train).sum() / float(no_train)*100\n",
    "    print(f\"目前正確率 {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. step 3: 預測 (testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model(x_test)\n",
    "_, predict_class = torch.max(predict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料正確率為 90.38%\n"
     ]
    }
   ],
   "source": [
    "acc = (predict_class == y_test).sum() / float(no_test)*100\n",
    "print(f\"測試資料正確率為 {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神經網路預測是: tensor(2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 9487\n",
    "\n",
    "print('神經網路預測是:', predict_class[n])\n",
    "plt.imshow(x_test[n].reshape(28,28), cmap='Greys');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-py37]",
   "language": "python",
   "name": "conda-env-torch-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
